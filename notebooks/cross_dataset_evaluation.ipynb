{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import random\n",
    "# from collections import defaultdict\n",
    "\n",
    "# print(\"Bắt đầu quá trình tái cấu trúc dataset cedarbhsig-260...\")\n",
    "\n",
    "# # --- CẤU HÌNH ---\n",
    "# # Đường dẫn gốc tới dataset bạn đã tìm thấy\n",
    "# BASE_BHSIG_DIR = '/kaggle/input/cedarbhsig-260/'\n",
    "# OUTPUT_FILE = '/kaggle/working/bhsig_restructured_split.json'\n",
    "# NUM_BENGALI_TEST_USERS = 50  # Số người dùng Bengali để test\n",
    "# NUM_HINDI_TEST_USERS = 30    # Số người dùng Hindi để test\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "# # --- CÁC THƯ MỤC NGUỒN ---\n",
    "# # Lưu ý: Các đường dẫn này dựa trên mô tả của bạn. Hãy kiểm tra lại nếu cần.\n",
    "# HINDI_GENUINE_DIR = os.path.join(BASE_BHSIG_DIR, 'Reconstructed_BHSig160-20250403T183033Z-001/Reconstructed_BHSig160/Genuine')\n",
    "# HINDI_FORGED_DIR = os.path.join(BASE_BHSIG_DIR, 'Reconstructed_BHSig160-20250403T183033Z-001/Reconstructed_BHSig160/Forged')\n",
    "# BENGALI_GENUINE_DIR = os.path.join(BASE_BHSIG_DIR, 'Reconstructed_BHSig100-20250403T193101Z-001/Reconstructed_BHSig100/Genuine')\n",
    "# BENGALI_FORGED_DIR = os.path.join(BASE_BHSIG_DIR, 'Reconstructed_BHSig100-20250403T193101Z-001/Reconstructed_BHSig100/Forged')\n",
    "\n",
    "# # --- HÀM TRÍCH XUẤT THÔNG TIN TỪ TÊN FILE ---\n",
    "# def parse_filename(filename):\n",
    "#     # Ví dụ: H-S-011-G-01.tif hoặc B-S-011-F-01.tif\n",
    "#     parts = filename.split('-')\n",
    "#     if len(parts) >= 4:\n",
    "#         language = parts[0]  # 'H' hoặc 'B'\n",
    "#         user_id = int(parts[2])\n",
    "#         return language, user_id\n",
    "#     return None, None\n",
    "\n",
    "# # --- THU THẬP VÀ PHÂN LOẠI FILE ---\n",
    "# all_files = defaultdict(lambda: {'genuine': [], 'forgery': []})\n",
    "# source_dirs = {\n",
    "#     'hindi_genuine': HINDI_GENUINE_DIR,\n",
    "#     'hindi_forged': HINDI_FORGED_DIR,\n",
    "#     'bengali_genuine': BENGALI_GENUINE_DIR,\n",
    "#     'bengali_forged': BENGALI_FORGED_DIR\n",
    "# }\n",
    "\n",
    "# for key, directory in source_dirs.items():\n",
    "#     if not os.path.exists(directory):\n",
    "#         print(f\"Cảnh báo: Không tìm thấy thư mục '{directory}'. Bỏ qua.\")\n",
    "#         continue\n",
    "        \n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.endswith('.tif'):\n",
    "#             lang, user_id = parse_filename(filename)\n",
    "#             if lang and user_id:\n",
    "#                 full_path = os.path.join(directory, filename)\n",
    "#                 # Tạo một ID người dùng duy nhất bằng cách kết hợp ngôn ngữ và ID\n",
    "#                 unique_user_id = f\"{lang}-{user_id}\"\n",
    "                \n",
    "#                 if 'genuine' in key:\n",
    "#                     all_files[unique_user_id]['genuine'].append(full_path)\n",
    "#                 elif 'forged' in key:\n",
    "#                     all_files[unique_user_id]['forgery'].append(full_path)\n",
    "\n",
    "# print(f\"Đã xử lý và phân loại file cho {len(all_files)} người dùng.\")\n",
    "\n",
    "# # --- CHỌN NGẪU NHIÊN NGƯỜI DÙNG ĐỂ TEST ---\n",
    "# bengali_users = [uid for uid in all_files if uid.startswith('B-')]\n",
    "# hindi_users = [uid for uid in all_files if uid.startswith('H-')]\n",
    "\n",
    "# random.seed(RANDOM_SEED)\n",
    "# random.shuffle(bengali_users)\n",
    "# random.shuffle(hindi_users)\n",
    "\n",
    "# test_bengali_ids = bengali_users[:NUM_BENGALI_TEST_USERS]\n",
    "# test_hindi_ids = hindi_users[:NUM_HINDI_TEST_USERS]\n",
    "\n",
    "# # --- TẠO FILE JSON CUỐI CÙNG ---\n",
    "# meta_test_data = {}\n",
    "# for user_id in test_bengali_ids + test_hindi_ids:\n",
    "#     meta_test_data[user_id] = all_files[user_id]\n",
    "\n",
    "# final_split_data = {'meta-test': meta_test_data}\n",
    "\n",
    "# with open(OUTPUT_FILE, 'w') as f:\n",
    "#     json.dump(final_split_data, f, indent=4)\n",
    "\n",
    "# print(\"\\n--- HOÀN TẤT TÁI CẤU TRÚC ---\")\n",
    "# print(f\"Đã tạo file split cho {len(test_bengali_ids)} người dùng Bengali và {len(test_hindi_ids)} người dùng Hindi.\")\n",
    "# print(f\"File được lưu tại: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-15T07:59:35.737177Z",
     "iopub.status.busy": "2025-10-15T07:59:35.737002Z",
     "iopub.status.idle": "2025-10-15T07:59:36.670081Z",
     "shell.execute_reply": "2025-10-15T07:59:36.669275Z",
     "shell.execute_reply.started": "2025-10-15T07:59:35.737161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update'...\n",
      "remote: Enumerating objects: 107, done.\u001b[K\n",
      "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
      "remote: Total 107 (delta 44), reused 84 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (107/107), 188.78 KiB | 2.66 MiB/s, done.\n",
      "Resolving deltas: 100% (44/44), done.\n",
      "/kaggle/working/Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update\n"
     ]
    }
   ],
   "source": [
    "# --- CÀI ĐẶT VÀ IMPORTS ---\n",
    "!rm -rf Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update\n",
    "!git clone https://github.com/trongjhuongwr/Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update.git\n",
    "%cd Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T07:59:36.672231Z",
     "iopub.status.busy": "2025-10-15T07:59:36.671870Z",
     "iopub.status.idle": "2025-10-15T07:59:45.874029Z",
     "shell.execute_reply": "2025-10-15T07:59:45.873113Z",
     "shell.execute_reply.started": "2025-10-15T07:59:36.672165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Imports từ modules của bạn\n",
    "from dataloader.meta_dataloader import SignatureEpisodeDataset\n",
    "from models.feature_extractor import ResNetFeatureExtractor\n",
    "from models.meta_learner import MetricGenerator\n",
    "from utils.model_evaluation import evaluate_meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T07:59:45.875406Z",
     "iopub.status.busy": "2025-10-15T07:59:45.874965Z",
     "iopub.status.idle": "2025-10-15T08:00:34.863870Z",
     "shell.execute_reply": "2025-10-15T08:00:34.863133Z",
     "shell.execute_reply.started": "2025-10-15T07:59:45.875379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 194MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đã tải thành công model huấn luyện trên CEDAR! ---\n",
      "\n",
      "--- Bắt đầu đánh giá Cross-Dataset trên BHSig-260 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- KẾT QUẢ CUỐI CÙNG ---\n",
      "Độ chính xác của model (train trên CEDAR) trên tập test BHSig-260: 82.04%\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# --- CẤU HÌNH VÀ THỰC THI ĐÁNH GIÁ ---\n",
    "\n",
    "# Cấu hình\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "K_SHOT = 10 # Số lượng mẫu support để mô hình \"học\" người dùng mới\n",
    "\n",
    "# Đường dẫn\n",
    "MODEL_DIR = '/kaggle/input/best-cedar-model-weights/best_cedar_model' # Sửa lại cho đúng tên dataset model của bạn\n",
    "BHSIG_SPLIT_FILE = '/kaggle/input/bhsig260-restructured-split/bhsig_restructured_split.json'\n",
    "\n",
    "# 1. Tải model đã huấn luyện trên CEDAR\n",
    "feature_extractor = ResNetFeatureExtractor(backbone_name='resnet34', output_dim=512)\n",
    "metric_generator = MetricGenerator(embedding_dim=512)\n",
    "\n",
    "fe_path = os.path.join(MODEL_DIR, 'best_feature_extractor.pth')\n",
    "mg_path = os.path.join(MODEL_DIR, 'best_metric_generator.pth')\n",
    "\n",
    "feature_extractor.load_state_dict(torch.load(fe_path))\n",
    "metric_generator.load_state_dict(torch.load(mg_path))\n",
    "\n",
    "feature_extractor.to(DEVICE)\n",
    "metric_generator.to(DEVICE)\n",
    "print(\"--- Đã tải thành công model huấn luyện trên CEDAR! ---\")\n",
    "\n",
    "# 2. Tạo dataset đánh giá trên BHSig-260\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((220, 150)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Vì dataloader của bạn đọc trực tiếp từ file split, chúng ta không cần base_data_dir\n",
    "bhsig_test_dataset = SignatureEpisodeDataset(\n",
    "    split_file_path=BHSIG_SPLIT_FILE, \n",
    "    base_data_dir=None,  # Đặt là None vì chúng ta dùng đường dẫn tuyệt đối\n",
    "    split_name='meta-test', \n",
    "    k_shot=K_SHOT, \n",
    "    n_query_genuine=15, \n",
    "    n_query_forgery=15, \n",
    "    augment=False,       # <-- Tắt augmentation khi đánh giá\n",
    "    use_full_path=True   # <-- Báo cho dataloader dùng đường dẫn tuyệt đối\n",
    ")\n",
    "\n",
    "# 3. Thực hiện đánh giá\n",
    "print(\"\\n--- Bắt đầu đánh giá Cross-Dataset trên BHSig-260 ---\")\n",
    "# Chúng ta cần đảm bảo hàm evaluate_meta_model cũng được cập nhật\n",
    "# Giả sử hàm evaluate_meta_model đã được cập nhật như trong các thảo luận trước\n",
    "cross_dataset_accuracy = evaluate_meta_model(\n",
    "    feature_extractor, \n",
    "    metric_generator, \n",
    "    bhsig_test_dataset, \n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\n\\n--- KẾT QUẢ CUỐI CÙNG ---\")\n",
    "print(f\"Độ chính xác của model (train trên CEDAR) trên tập test BHSig-260: {cross_dataset_accuracy * 100:.2f}%\")\n",
    "print(\"----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7043317,
     "sourceId": 11267662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8496202,
     "sourceId": 13389726,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8496752,
     "sourceId": 13390523,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
