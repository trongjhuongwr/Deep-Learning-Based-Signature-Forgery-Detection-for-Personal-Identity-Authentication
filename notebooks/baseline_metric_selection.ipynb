{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# PHASE 1: Baseline Metric Selection for Pre-training (K-Fold Comparison)\n",
        "\n",
        "This notebook runs K-Fold cross-validation to compare fixed distance metrics (Euclidean, Cosine, Manhattan) and prepares the best pre-trained feature extractor for meta-training.\n",
        "\n",
        "The environment setup and file paths have been updated to clone the repository and use paths relative to the cloned repo and Kaggle input structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Environment Setup: clone the repository and change working directory ===\n",
        "# Ensure the latest version of the code is used\n",
        "!rm -rf Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update\n",
        "!git clone https://github.com/trongjhuongwr/Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update.git\n",
        "%cd Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Imports and repo path setup ===\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Add the current repo root to sys.path so imports resolve\n",
        "BASE_DIR = os.path.abspath(os.getcwd())\n",
        "sys.path.append(BASE_DIR)\n",
        "print(f\"Repo base directory: {BASE_DIR}\")\n",
        "\n",
        "# Import from the project (modules expected in the cloned repo)\n",
        "from utils.helpers import load_config\n",
        "from models.Triplet_Siamese_Similarity_Network import tSSN\n",
        "from models.feature_extractor import ResNetFeatureExtractor\n",
        "from losses.triplet_loss import TripletLoss\n",
        "from dataloader.tSSN_trainloader import SignaturePretrainDataset\n",
        "\n",
        "print(\"Imports completed and seed set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Set global seed for reproducibility ===\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(\"Random seed and torch backend configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Helper functions and small classes ===\n",
        "import re\n",
        "from PIL import Image\n",
        "from itertools import combinations\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def _get_user_id_from_filename(filename):\n",
        "    \"\"\"Extract user ID from a filename (CEDAR or BHSig style).\"\"\"\n",
        "    match = re.search(r'_(\\d+)_', filename)  # CEDAR-style\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    match = re.search(r'-(\\d+)-', filename)  # BHSig-style\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SignaturePairDataset(Dataset):\n",
        "    \"\"\"Dataset that builds PAIRS for evaluation (genuine vs forged).\"\"\"\n",
        "    def __init__(self, org_dir, forg_dir, user_ids, transform=None):\n",
        "        self.transform = transform\n",
        "        self.pairs = []\n",
        "        self.user_map = {}\n",
        "        supported_extensions = ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp')\n",
        "        user_ids_set = set(user_ids)\n",
        "\n",
        "        # collect genuine images per user\n",
        "        for f in os.listdir(org_dir):\n",
        "            if f.lower().endswith(supported_extensions):\n",
        "                user_id = _get_user_id_from_filename(f)\n",
        "                if user_id in user_ids_set:\n",
        "                    if user_id not in self.user_map:\n",
        "                        self.user_map[user_id] = {'genuine': [], 'forged': []}\n",
        "                    self.user_map[user_id]['genuine'].append(os.path.join(org_dir, f))\n",
        "\n",
        "        # collect forged images per user\n",
        "        for f in os.listdir(forg_dir):\n",
        "            if f.lower().endswith(supported_extensions):\n",
        "                user_id = _get_user_id_from_filename(f)\n",
        "                if user_id in user_ids_set:\n",
        "                    if user_id not in self.user_map:\n",
        "                        continue\n",
        "                    self.user_map[user_id]['forged'].append(os.path.join(forg_dir, f))\n",
        "\n",
        "        # build pairs: genuine-genuine (label=1) and genuine-forged (label=0)\n",
        "        for user_id in self.user_map:\n",
        "            genuine_list = self.user_map[user_id]['genuine']\n",
        "            forged_list = self.user_map[user_id]['forged']\n",
        "            for (img_path1, img_path2) in combinations(genuine_list, 2):\n",
        "                self.pairs.append((img_path1, img_path2, 1))\n",
        "            for gen_path in genuine_list:\n",
        "                for forg_path in forged_list:\n",
        "                    self.pairs.append((gen_path, forg_path, 0))\n",
        "\n",
        "        if not self.pairs:\n",
        "            print(f\"Warning: No pairs created for user_ids: {user_ids}.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path1, img_path2, label = self.pairs[idx]\n",
        "        try:\n",
        "            img1 = Image.open(img_path1).convert('L')\n",
        "            img2 = Image.open(img_path2).convert('L')\n",
        "            if self.transform:\n",
        "                img1 = self.transform(img1)\n",
        "                img2 = self.transform(img2)\n",
        "            return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}. Returning None.\")\n",
        "            return None\n",
        "\n",
        "def collate_fn_skip_none(batch):\n",
        "    \"\"\"Custom collate function that skips failed items (None).\"\"\"\n",
        "    batch = list(filter(lambda x: x is not None, batch))\n",
        "    if not batch:\n",
        "        return torch.empty(0), torch.empty(0), torch.empty(0)\n",
        "    return torch.utils.data.dataloader.default_collate(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EER / FAR / FRR helper ===\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "def calculate_far_frr_eer(true_labels, distances):\n",
        "    \"\"\"Compute EER and threshold from arrays of true_labels and distances.\"\"\"\n",
        "    true_labels = np.array(true_labels)\n",
        "    distances = np.array(distances)\n",
        "    finite_mask = np.isfinite(distances)\n",
        "    if not np.any(finite_mask):\n",
        "        return 1.0, np.nan\n",
        "    true_labels = true_labels[finite_mask]\n",
        "    distances = distances[finite_mask]\n",
        "    if len(np.unique(true_labels)) < 2 or len(distances) == 0:\n",
        "        return 1.0, np.nan\n",
        "    min_dist, max_dist = np.min(distances), np.max(distances)\n",
        "    thresholds = np.linspace(min_dist - 1e-6, max_dist + 1e-6, num=500)\n",
        "    far_list = []\n",
        "    frr_list = []\n",
        "    for thresh in thresholds:\n",
        "        predictions = (distances < thresh).astype(int)\n",
        "        tp = np.sum((predictions == 1) & (true_labels == 1))\n",
        "        fp = np.sum((predictions == 1) & (true_labels == 0))\n",
        "        tn = np.sum((predictions == 0) & (true_labels == 0))\n",
        "        fn = np.sum((predictions == 0) & (true_labels == 1))\n",
        "        far = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "        frr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
        "        far_list.append(far)\n",
        "        frr_list.append(frr)\n",
        "    far_list = np.array(far_list)\n",
        "    frr_list = np.array(frr_list)\n",
        "    eer_index = np.nanargmin(np.abs(far_list - frr_list))\n",
        "    eer = (far_list[eer_index] + frr_list[eer_index]) / 2.0\n",
        "    eer_threshold = thresholds[eer_index]\n",
        "    return eer, eer_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Train epoch and pair-evaluation functions ===\n",
        "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for item in dataloader:\n",
        "        if isinstance(item, tuple) and len(item) == 3 and item[0].nelement() == 0:\n",
        "            continue\n",
        "        anchor, positive, negative = item\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        anchor_feat, positive_feat, negative_feat = model(anchor, positive, negative)\n",
        "        loss = loss_fn(anchor_feat, positive_feat, negative_feat)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "    return (total_loss / num_batches) if num_batches > 0 else 0.0\n",
        "\n",
        "def evaluate_on_pairs(model, dataloader, device, distance_mode='euclidean'):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_distances = []\n",
        "    with torch.no_grad():\n",
        "        for item in dataloader:\n",
        "            if isinstance(item, tuple) and len(item) == 3 and item[0].nelement() == 0:\n",
        "                continue\n",
        "            img1, img2, label = item\n",
        "            img1, img2 = img1.to(device), img2.to(device)\n",
        "            feat1 = model.feature_extractor(img1)\n",
        "            feat2 = model.feature_extractor(img2)\n",
        "            if distance_mode == 'euclidean':\n",
        "                distances = F.pairwise_distance(feat1, feat2, p=2)\n",
        "            elif distance_mode == 'cosine':\n",
        "                distances = 1.0 - F.cosine_similarity(feat1, feat2, dim=1)\n",
        "            elif distance_mode == 'manhattan':\n",
        "                distances = F.pairwise_distance(feat1, feat2, p=1)\n",
        "            else:\n",
        "                distances = F.pairwise_distance(feat1, feat2, p=2)\n",
        "            all_distances.extend(distances.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    if not all_labels or not all_distances:\n",
        "        return 1.0, 0.0, 0.0\n",
        "    eer, eer_threshold = calculate_far_frr_eer(all_labels, all_distances)\n",
        "    roc_scores = -np.array(all_distances)\n",
        "    roc_auc = roc_auc_score(all_labels, roc_scores)\n",
        "    predictions = (np.array(all_distances) < eer_threshold).astype(int)\n",
        "    accuracy = accuracy_score(all_labels, predictions)\n",
        "    return eer, roc_auc, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a06ebc",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_SPLITS = 5\n",
        "BASE_DATA_DIR = '/kaggle/input/cedardataset/signatures'\n",
        "SPLIT_FILES_DIR = '/kaggle/working/Deep-Learning-Based-Signature-Forgery-Detection-for-Personal-Identity-Authentication-Update/scripts/prepare_kfold_splits'\n",
        "\n",
        "print(\"Generating K-Fold split files...\")\n",
        "os.makedirs(SPLIT_FILES_DIR, exist_ok=True)\n",
        "\n",
        "script_path = 'scripts/prepare_kfold_splits.py'\n",
        "command = f\"python {script_path} --base_data_dir {BASE_DATA_DIR} --output_dir {SPLIT_FILES_DIR} --seed {SEED} --num_splits {NUM_SPLITS}\"\n",
        "\n",
        "print(f\"Running command: {command}\")\n",
        "!{command}\n",
        "\n",
        "created_files = os.listdir(SPLIT_FILES_DIR)\n",
        "print(f\"Generated files in {SPLIT_FILES_DIR}: {created_files}\")\n",
        "if len(created_files) != NUM_SPLITS:\n",
        "    print(f\"Warning: Expected {NUM_SPLITS} split files, but found {len(created_files)}.\")\n",
        "else:\n",
        "    print(\"K-Fold split files generated successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Load config, define data dirs, and K-Fold split path ===\n",
        "config = load_config(os.path.join(BASE_DIR, 'configs', 'config_tSSN.yaml'))\n",
        "\n",
        "# Default Kaggle dataset folder name (adjust if different)\n",
        "KAGGLE_CEDAR_DATASET_NAME = 'cedardataset'\n",
        "KAGGLE_BASE = f'/kaggle/input/{KAGGLE_CEDAR_DATASET_NAME}'\n",
        "DATA_DIR = os.path.join(KAGGLE_BASE, 'signatures')\n",
        "ORG_DIR = os.path.join(DATA_DIR, 'full_org')\n",
        "FORG_DIR = os.path.join(DATA_DIR, 'full_forg')\n",
        "\n",
        "# K-Fold split JSON assumed to be inside repo root or created previously\n",
        "SPLIT_FILE_PATH = os.path.join(BASE_DIR, 'kfold_splits_cedar_5.json')\n",
        "\n",
        "print('Configuration:')\n",
        "print('  ORG_DIR =', ORG_DIR)\n",
        "print('  FORG_DIR =', FORG_DIR)\n",
        "print('  SPLIT_FILE_PATH =', SPLIT_FILE_PATH)\n",
        "\n",
        "if not os.path.isdir(ORG_DIR) or not os.path.isdir(FORG_DIR):\n",
        "    print('WARNING: Data directories do not exist. Please ensure the Kaggle dataset is added.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Define transform and device ===\n",
        "input_size = tuple(config['dataset']['input_size'])\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Load K-Fold splits JSON ===\n",
        "K_FOLDS = 5\n",
        "if not os.path.exists(SPLIT_FILE_PATH):\n",
        "    raise FileNotFoundError(f\"Split file not found at {SPLIT_FILE_PATH}. Please generate it first.\")\n",
        "with open(SPLIT_FILE_PATH, 'r') as f:\n",
        "    kfold_splits = json.load(f)\n",
        "if len(kfold_splits) != K_FOLDS:\n",
        "    print(f\"Warning: expected {K_FOLDS} folds, found {len(kfold_splits)}\")\n",
        "print(f\"Loaded {len(kfold_splits)} fold entries.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Experiment configuration ===\n",
        "NUM_EPOCHS_PER_FOLD = config['training']['num_epochs']\n",
        "MODES_TO_TEST = ['euclidean', 'cosine', 'manhattan']\n",
        "MARGINS_TO_TEST = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "results_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Run K-Fold experiments ===\n",
        "print(f\"Running experiments: modes={MODES_TO_TEST} margins={MARGINS_TO_TEST} epochs={NUM_EPOCHS_PER_FOLD}\")\n",
        "\n",
        "for mode in MODES_TO_TEST:\n",
        "    for margin in MARGINS_TO_TEST:\n",
        "        fold_metrics = {'eer': [], 'roc_auc': [], 'accuracy': [], 'train_loss': []}\n",
        "        config_name = f\"mode={mode}_margin={margin}\"\n",
        "        print(f\"\\n--- Experiment: {config_name} ---\")\n",
        "        for fold_data in kfold_splits:\n",
        "            fold_index = fold_data['fold']\n",
        "            train_users = fold_data['train_users']\n",
        "            val_users = fold_data['val_users']\n",
        "            print(f\"  Fold {fold_index}/{len(kfold_splits)}\")\n",
        "            model = tSSN(backbone_name=config['model']['backbone'], output_dim=config['model']['feature_dim'], pretrained=True).to(device)\n",
        "            loss_fn = TripletLoss(margin=margin, mode=mode).to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
        "            # prepare train triplet dataset and filter by train_users\n",
        "            train_triplet_dataset = SignaturePretrainDataset(org_dir=ORG_DIR, forg_dir=FORG_DIR, transform=transform)\n",
        "            train_triplet_dataset.triplets = [\n",
        "                t for t in train_triplet_dataset.triplets\n",
        "                if _get_user_id_from_filename(os.path.basename(t[0])) in train_users\n",
        "            ]\n",
        "            print(f\"    Train triplets: {len(train_triplet_dataset)} from {len(train_users)} users\")\n",
        "            val_pair_dataset = SignaturePairDataset(org_dir=ORG_DIR, forg_dir=FORG_DIR, user_ids=val_users, transform=transform)\n",
        "            print(f\"    Val pairs: {len(val_pair_dataset)} from {len(val_users)} users\")\n",
        "            train_loader = DataLoader(train_triplet_dataset, batch_size=config['training']['batch_size'], shuffle=True, num_workers=2, collate_fn=collate_fn_skip_none)\n",
        "            val_loader = DataLoader(val_pair_dataset, batch_size=config['training']['batch_size']*2, shuffle=False, num_workers=2, collate_fn=collate_fn_skip_none)\n",
        "            if len(train_loader) == 0 or len(val_loader) == 0:\n",
        "                print(f\"    Skipping fold {fold_index} due to no data\")\n",
        "                continue\n",
        "            avg_train_loss = 0.0\n",
        "            for epoch in range(NUM_EPOCHS_PER_FOLD):\n",
        "                train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
        "                avg_train_loss += train_loss\n",
        "                if epoch == NUM_EPOCHS_PER_FOLD - 1:\n",
        "                    eer, roc_auc, acc = evaluate_on_pairs(model, val_loader, device, distance_mode=mode)\n",
        "                    print(f\"    Fold {fold_index} final: Train Loss {train_loss:.4f}, Val EER {eer:.4f}, ROC-AUC {roc_auc:.4f}\")\n",
        "                    fold_metrics['eer'].append(eer)\n",
        "                    fold_metrics['roc_auc'].append(roc_auc)\n",
        "                    fold_metrics['accuracy'].append(acc)\n",
        "                    fold_metrics['train_loss'].append(avg_train_loss / NUM_EPOCHS_PER_FOLD)\n",
        "        mean_eer = np.mean(fold_metrics['eer']) if fold_metrics['eer'] else 1.0\n",
        "        mean_roc_auc = np.mean(fold_metrics['roc_auc']) if fold_metrics['roc_auc'] else 0.0\n",
        "        mean_acc = np.mean(fold_metrics['accuracy']) if fold_metrics['accuracy'] else 0.0\n",
        "        mean_loss = np.mean(fold_metrics['train_loss']) if fold_metrics['train_loss'] else np.nan\n",
        "        print(f\"  >> {config_name} Mean EER {mean_eer:.4f} ROC_AUC {mean_roc_auc:.4f} Acc {mean_acc:.4f}\")\n",
        "        results_data.append({'mode': mode, 'margin': margin, 'mean_eer': mean_eer, 'mean_roc_auc': mean_roc_auc, 'mean_accuracy': mean_acc, 'mean_train_loss': mean_loss})\n",
        "print(\"\\nAll experiments completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Analyze results and pick best config ===\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results_data)\n",
        "print('Results summary:')\n",
        "print(results_df.to_markdown(index=False, floatfmt='.4f'))\n",
        "results_df = results_df.sort_values(by=['mean_eer', 'mean_roc_auc'], ascending=[True, False])\n",
        "print('\\nRanking (best first):')\n",
        "print(results_df.to_markdown(index=False, floatfmt='.4f'))\n",
        "best_config = results_df.iloc[0]\n",
        "print('\\nSelected best config:')\n",
        "print(best_config.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # === Optional: final training on all data with the selected config and save feature extractor ===\n",
        "# BEST_MODE = best_config['mode']\n",
        "# BEST_MARGIN = best_config['margin']\n",
        "# FINAL_EPOCHS = NUM_EPOCHS_PER_FOLD\n",
        "# SAVE_PATH = os.path.join('/kaggle/working', 'models', 'baseline_best_feature_extractor.pth')\n",
        "# final_model = tSSN(backbone_name=config['model']['backbone'], output_dim=config['model']['feature_dim'], pretrained=True).to(device)\n",
        "# final_loss_fn = TripletLoss(margin=BEST_MARGIN, mode=BEST_MODE).to(device)\n",
        "# final_optimizer = optim.Adam(final_model.parameters(), lr=config['training']['learning_rate'])\n",
        "# final_train_dataset = SignaturePretrainDataset(org_dir=ORG_DIR, forg_dir=FORG_DIR, transform=transform)\n",
        "# final_train_loader = DataLoader(final_train_dataset, batch_size=config['training']['batch_size'], shuffle=True, num_workers=2, collate_fn=collate_fn_skip_none)\n",
        "# print(f\"Final training on {len(final_train_dataset)} triplets\")\n",
        "# if len(final_train_loader) > 0:\n",
        "#     for epoch in tqdm(range(FINAL_EPOCHS), desc='Final training'):\n",
        "#         loss = train_epoch(final_model, final_train_loader, final_loss_fn, final_optimizer, device)\n",
        "#         if (epoch+1) % 10 == 0:\n",
        "#             print(f\"Epoch {epoch+1}/{FINAL_EPOCHS} loss {loss:.4f}\")\n",
        "#     os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "#     torch.save(final_model.feature_extractor.state_dict(), SAVE_PATH)\n",
        "#     print('Saved final feature extractor to', SAVE_PATH)\n",
        "# else:\n",
        "#     print('No data for final training.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
