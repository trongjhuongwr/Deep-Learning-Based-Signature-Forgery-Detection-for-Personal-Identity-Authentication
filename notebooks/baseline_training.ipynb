{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Environment Setup: Install and import required package**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:43:41.095739Z",
     "iopub.status.busy": "2025-05-15T13:43:41.095462Z",
     "iopub.status.idle": "2025-05-15T13:44:53.869217Z",
     "shell.execute_reply": "2025-05-15T13:44:53.868492Z",
     "shell.execute_reply.started": "2025-05-15T13:43:41.095724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install the pakage\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:44:53.871791Z",
     "iopub.status.busy": "2025-05-15T13:44:53.871358Z",
     "iopub.status.idle": "2025-05-15T13:45:01.070490Z",
     "shell.execute_reply": "2025-05-15T13:45:01.069852Z",
     "shell.execute_reply.started": "2025-05-15T13:44:53.871768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import module\n",
    "from utils.helpers import load_config, save_model, train_model, train_model_kfold\n",
    "from utils.model_evaluation import draw_plot_find_acc\n",
    "from models.Triplet_Siamese_Similarity_Network import tSSN\n",
    "from losses.triplet_loss import TripletLoss\n",
    "from dataloader.tSSN_trainloader import SignatureTrainDataset\n",
    "\n",
    "print(\"Package installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.071495Z",
     "iopub.status.busy": "2025-05-15T13:45:01.071130Z",
     "iopub.status.idle": "2025-05-15T13:45:01.082364Z",
     "shell.execute_reply": "2025-05-15T13:45:01.081725Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.071475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Set global seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Setup: Load configuration and prepare training dataset**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.083441Z",
     "iopub.status.busy": "2025-05-15T13:45:01.083070Z",
     "iopub.status.idle": "2025-05-15T13:45:01.691628Z",
     "shell.execute_reply": "2025-05-15T13:45:01.690807Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.083418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Transform chung\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((220, 150)),\n",
    "    transforms.Grayscale(),  # Đảm bảo ảnh 1 kênh xám\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = SignatureTrainDataset(\n",
    "    org_dir=r'/kaggle/input/cedardataset/signatures/full_org',\n",
    "    forg_dir=r'/kaggle/input/cedardataset/signatures/full_forg',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, len(dataset) - train_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, num_workers=4, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, num_workers=4, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.692808Z",
     "iopub.status.busy": "2025-05-15T13:45:01.692550Z",
     "iopub.status.idle": "2025-05-15T13:45:01.833727Z",
     "shell.execute_reply": "2025-05-15T13:45:01.832963Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.692779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check Dataset\n",
    "print(f\"Dataset - Total triplets: {len(dataset)}\")\n",
    "\n",
    "anchor, positive, negative = dataset[0]\n",
    "\n",
    "print(f\"Anchor shape: {anchor.shape}\")\n",
    "print(f\"Positive shape: {positive.shape}\")\n",
    "print(f\"Negative shape: {negative.shape}\")\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset)}\")\n",
    "\n",
    "anchor_train, positive_train, negative_train = train_dataset[0]\n",
    "\n",
    "print(f\"Anchor shape: {anchor_train.shape}\")\n",
    "print(f\"Positive shape: {positive_train.shape}\")\n",
    "print(f\"Negative shape: {negative_train.shape}\")\n",
    "\n",
    "print(f\"Testing dataset: {len(test_dataset)}\")\n",
    "\n",
    "anchor_test, positive_test, negative_test = test_dataset[0]\n",
    "\n",
    "print(f\"Anchor shape: {anchor_test.shape}\")\n",
    "print(f\"Positive shape: {positive_test.shape}\")\n",
    "print(f\"Negative shape: {negative_test.shape}\")\n",
    "\n",
    "print(\"LOAD DATASET SUCCESSFULLY\")\n",
    "print(f\"Train-Test Split Ratio: {len(train_dataset)/len(dataset)*100:.1f}% - {len(test_dataset)/len(dataset)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.834706Z",
     "iopub.status.busy": "2025-05-15T13:45:01.834420Z",
     "iopub.status.idle": "2025-05-15T13:45:01.842225Z",
     "shell.execute_reply": "2025-05-15T13:45:01.841497Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.834665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load experiment configuration (e.g., training settings)\n",
    "config = load_config(r'/kaggle/working/Deep_Learning-Based_Signature_Forgery_Detection_for_Personal_Identity_Authentication/configs/config_tSSN.yaml')\n",
    "print(config)\n",
    "print(\"LOAD CONFIG SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Experiment: Triplet Loss with different distance modes and margins (5-fold CV)**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T13:45:01.843199Z",
     "iopub.status.busy": "2025-05-15T13:45:01.842943Z",
     "iopub.status.idle": "2025-05-15T15:44:54.481128Z",
     "shell.execute_reply": "2025-05-15T15:44:54.480297Z",
     "shell.execute_reply.started": "2025-05-15T13:45:01.843175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the different distance metrics to be used in triplet loss\n",
    "modes = ['euclidean', 'cosine', 'manhattan', 'learnable']\n",
    "\n",
    "# Define a range of margin values for static (non-learnable) triplet loss\n",
    "margins = np.arange(0.2, 1.01, 0.2)\n",
    "\n",
    "# Dictionary to store cross-validation results for each configuration\n",
    "results_dict:dict = {}\n",
    "\n",
    "# Iterate through each distance mode\n",
    "for mode in modes:\n",
    "    if mode == 'learnable':\n",
    "        print(f\"\\nTraining mode: {mode} | margin: learnable\")\n",
    "\n",
    "        # Initialize Triplet Loss with learnable margin\n",
    "        loss_fn = TripletLoss(\n",
    "                margin=margin, # `margin` should be defined globally if using learnable\n",
    "                mode=mode,\n",
    "                input_dim=config['model']['feature_dim']\n",
    "        )\n",
    "        \n",
    "        # Perform K-Fold cross-validation training\n",
    "        mean_acc, mean_loss = train_model_kfold(\n",
    "            config=config,\n",
    "            loss_fn=loss_fn,\n",
    "            dataset=train_dataset,\n",
    "            k_folds=10\n",
    "        )\n",
    "\n",
    "        results_dict[f\"{mode}\"] = {\n",
    "            'mean_acc': mean_acc,\n",
    "            'mean_loss': mean_loss\n",
    "        }\n",
    "    else:\n",
    "        for margin in margins:\n",
    "            print(f\"\\nTraining mode: {mode} | margin: {margin:.1f}\")\n",
    "                    \n",
    "            # Initialize Triplet Loss with fixed margin\n",
    "            loss_fn = TripletLoss(\n",
    "                margin=margin,\n",
    "                mode=mode,\n",
    "                input_dim=config['model']['feature_dim']\n",
    "            )\n",
    "\n",
    "            # Perform K-Fold cross-validation training\n",
    "            mean_acc, mean_loss = train_model_kfold(\n",
    "                config=config,\n",
    "                loss_fn=loss_fn,\n",
    "                dataset=train_dataset,\n",
    "                k_folds=10\n",
    "            )\n",
    "            results_dict[f\"{mode}_{margin:.1f}\"] = {\n",
    "                'mean_acc': mean_acc,\n",
    "                'mean_loss': mean_loss\n",
    "            }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy results and extract the best-performing configuration\n",
    "best_params = draw_plot_find_acc(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Final Training with Best Parameters and Model Export**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Re-train model on full dataset using best parameters\n",
    "best_mode = best_params['mode']\n",
    "best_margin = best_params['margin']\n",
    "save_path = f\"/kaggle/working/final\"\n",
    "\n",
    "model = tSSN(config['model']['backbone'], config['model']['feature_dim'])\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "loss_fn = TripletLoss(\n",
    "    margin=0 if best_mode == 'learnable' else best_margin,\n",
    "    mode=best_mode,\n",
    "    input_dim=config['model']['feature_dim']\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "\n",
    "# Final training (use full dataset, no cross-validation)\n",
    "model, final_train_loss = train_model(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=config['training']['num_epochs'],\n",
    "    device=device,\n",
    "    early_stop=config['training']['early_stop']\n",
    ")\n",
    "\n",
    "# Save model to disk (e.g., for Kaggle submission or later inference)\n",
    "save_model(model=model,\n",
    "        dir= save_path,     \n",
    "        optimizer=optimizer,\n",
    "        avg_loss=final_train_loss,\n",
    "        model_name=f\"tSNN_{best_mode}_{best_margin:.1f}\")\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Export Model and Upload to Kaggle**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:44:54.483950Z",
     "iopub.status.busy": "2025-05-15T15:44:54.483709Z",
     "iopub.status.idle": "2025-05-15T15:47:41.840187Z",
     "shell.execute_reply": "2025-05-15T15:47:41.839590Z",
     "shell.execute_reply.started": "2025-05-15T15:44:54.483929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Up load model\n",
    "import kagglehub\n",
    "\n",
    "kagglehub.login()\n",
    "\n",
    "kagglehub.model_upload(\n",
    "    handle=\"...\",\n",
    "    local_model_dir=\"/kaggle/working/final\",\n",
    "    version_notes=\"Upload latest model with best parameters\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1512017,
     "sourceId": 2497231,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
